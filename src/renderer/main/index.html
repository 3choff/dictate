<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Dictate</title>
    <link rel="stylesheet" href="../main/styles.css">
</head>
<body>
    <div class="container">
        <div class="top-bar">
            <div class="drag-indicator-container">
                <div class="drag-indicator"></div>
            </div>
            <div class="close-button" id="close-btn">
                <svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M1 1L11 11M1 11L11 1" stroke="white" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </div>
        </div>
        <div class="main-content">
            <div class="icon-button settings-icon">
                <svg viewBox="0 0 32 32" enable-background="new 0 0 32 32" id="Editable-line" version="1.1" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"><circle cx="16" cy="16" fill="none" id="XMLID_224_" r="4" stroke="#e8eaed" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" stroke-width="2"></circle><path d=" M27.758,10.366l-1-1.732c-0.552-0.957-1.775-1.284-2.732-0.732L23.5,8.206C21.5,9.36,19,7.917,19,5.608V5c0-1.105-0.895-2-2-2h-2 c-1.105,0-2,0.895-2,2v0.608c0,2.309-2.5,3.753-4.5,2.598L7.974,7.902C7.017,7.35,5.794,7.677,5.242,8.634l-1,1.732 c-0.552,0.957-0.225,2.18,0.732,2.732L5.5,13.402c2,1.155,2,4.041,0,5.196l-0.526,0.304c-0.957,0.552-1.284,1.775-0.732,2.732 l1,1.732c0.552,0.957,1.775,1.284,2.732,0.732L8.5,23.794c2-1.155,4.5,0.289,4.5,2.598V27c0,1.105,0.895,2,2,2h2 c1.105,0,2-0.895,2-2v-0.608c0-2.309,2.5-3.753,4.5-2.598l0.526,0.304c0.957,0.552,2.18,0.225,2.732-0.732l1-1.732 c0.552-0.957,0.225-2.18-0.732-2.732L26.5,18.598c-2-1.155-2-4.041,0-5.196l0.526-0.304C27.983,12.546,28.311,11.323,27.758,10.366z " fill="none" id="XMLID_242_" stroke="#e8eaed" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" stroke-width="2"></path></g></svg>
            </div>
            <div class="mic-button">
                <svg viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <path fill-rule="evenodd" clip-rule="evenodd" d="M14.5 10.5V5.5C14.5 4.11929 13.3807 3 12 3C10.6193 3 9.5 4.11929 9.5 5.5V10.5C9.5 11.8807 10.6193 13 12 13C13.3807 13 14.5 11.8807 14.5 10.5ZM12 1C9.51472 1 7.5 3.01472 7.5 5.5V10.5C7.5 12.9853 9.51472 15 12 15C14.4853 15 16.5 12.9853 16.5 10.5V5.5C16.5 3.01472 14.4853 1 12 1Z" fill="#8ab4f8"></path> <path d="M12 17C5.49999 17 5.99999 12 5.99999 12C5.99999 12 6.00001 11 5.00001 11C4.00001 11 3.99999 12 3.99999 12C3.99999 12 3.54013 18.4382 11 18.9657V22C11 22.5523 11.4477 23 12 23C12.5523 23 13 22.5523 13 22V18.9657C20.4599 18.4382 20 12 20 12C20 12 20 11 19 11C18 11 18 12 18 12C18 12 18.5 17 12 17Z" fill="#8ab4f8"></path> </g></svg>
            </div>
            <div class="icon-button help-icon">
                <svg viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <path d="M23 12C23 18.0751 18.0751 23 12 23C5.92487 23 1 18.0751 1 12C1 5.92487 5.92487 1 12 1C18.0751 1 23 5.92487 23 12ZM3.00683 12C3.00683 16.9668 7.03321 20.9932 12 20.9932C16.9668 20.9932 20.9932 16.9668 20.9932 12C20.9932 7.03321 16.9668 3.00683 12 3.00683C7.03321 3.00683 3.00683 7.03321 3.00683 12Z" fill="#e8eaed"></path> <path d="M13.5 18C13.5 18.8284 12.8284 19.5 12 19.5C11.1716 19.5 10.5 18.8284 10.5 18C10.5 17.1716 11.1716 16.5 12 16.5C12.8284 16.5 13.5 17.1716 13.5 18Z" fill="#e8eaed"></path> <path d="M11 12V14C11 14 11 15 12 15C13 15 13 14 13 14V12C13 12 13.4792 11.8629 13.6629 11.7883C13.6629 11.7883 13.9969 11.6691 14.2307 11.4896C14.4646 11.3102 14.6761 11.097 14.8654 10.8503C15.0658 10.6035 15.2217 10.3175 15.333 9.99221C15.4443 9.66693 15.5 9.4038 15.5 9C15.5 8.32701 15.3497 7.63675 15.0491 7.132C14.7596 6.61604 14.3476 6.21786 13.8132 5.93745C13.2788 5.64582 12.6553 5.5 11.9427 5.5C11.4974 5.5 11.1021 5.55608 10.757 5.66825C10.4118 5.7692 10.1057 5.9094 9.83844 6.08887C9.58236 6.25712 9.36525 6.4478 9.18711 6.66091C9.02011 6.86281 8.8865 7.0591 8.78629 7.24978C8.68609 7.44046 8.61929 7.6087 8.58589 7.75452C8.51908 7.96763 8.49125 8.14149 8.50238 8.27609C8.52465 8.41069 8.59145 8.52285 8.70279 8.61258C8.81413 8.70231 8.9867 8.79765 9.22051 8.8986C9.46546 8.97712 9.65473 9.00516 9.78834 8.98273C9.93308 8.96029 10.05 8.89299 10.1391 8.78083C10.1391 8.78083 10.6138 8.10569 10.7474 7.97109C10.8922 7.82528 11.0703 7.71312 11.2819 7.6346C11.4934 7.54487 11.7328 7.5 12 7.5C12.579 7.5 13.0076 7.64021 13.286 7.92062C13.5754 8.18982 13.6629 8.41629 13.6629 8.93225C13.6629 9.27996 13.6017 9.56038 13.4792 9.77349C13.3567 9.9866 13.1953 10.1605 12.9949 10.2951C12.9949 10.2951 12.7227 10.3991 12.5 10.5C12.2885 10.5897 11.9001 10.7381 11.6997 10.8503C11.5104 10.9512 11.4043 11.0573 11.2819 11.2144C11.1594 11.3714 11 11.7308 11 12Z" fill="#e8eaed"></path> </g></svg>
            </div>
        </div>
    </div>
    <script src="../../shared/deepgram.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        const closeBtn = document.getElementById('close-btn');
        const settingsIcon = document.querySelector('.settings-icon');
        const helpButton = document.querySelector('.help-icon');
        const micButton = document.querySelector('.mic-button');
        let mediaRecorder;
        let audioChunks = [];
        let dgSocket = null;
        let dgActive = false;
        // Groq (Whisper) simple silence-based segmenter state
        let groqActive = false;
        let groqAudioCtx = null;
        let groqSource = null;
        let groqProcessor = null;
        let groqSamples16k = []; // plain Number[] of int16 samples at 16kHz
        let groqLastBoundary = 0; // index in 16k sample domain
        let groqInSilenceMs = 0;
        let groqHadSpeech = false;
        const GROQ_SILENCE_MS = 1000; // silence of 1s
        const GROQ_SILENCE_DB = -30; // classify more as silence
        const GROQ_MAX_SEGMENT_MS = 15000; // safety cut at 15s
        const GROQ_MIN_SEGMENT_MS = 200; // ignore ultra-short noise-only

        function dbfsFromRms(rms) {
            if (rms <= 1e-9) return -120;
            return 20 * Math.log10(rms);
        }

        function mixToMonoFloat32(audioBuffer) {
            const ch = audioBuffer.numberOfChannels;
            if (ch === 1) {
                return audioBuffer.getChannelData(0);
            }
            const len = audioBuffer.length;
            const out = new Float32Array(len);
            for (let c = 0; c < ch; c++) {
                const data = audioBuffer.getChannelData(c);
                for (let i = 0; i < len; i++) out[i] += data[i];
            }
            for (let i = 0; i < len; i++) out[i] /= ch;
            return out;
        }

        // Downsample arbitrary input rate to 16k and quantize to Int16
        function downsampleTo16kInt16(float32Mono, inputSampleRate) {
            const targetRate = 16000;
            const ratio = inputSampleRate / targetRate;
            const newLength = Math.floor(float32Mono.length / ratio);
            const out = new Int16Array(newLength);
            let iOut = 0;
            for (let i = 0; i < newLength; i++) {
                const start = Math.floor(i * ratio);
                const end = Math.floor((i + 1) * ratio);
                let sum = 0;
                let count = 0;
                for (let j = start; j < end && j < float32Mono.length; j++) {
                    sum += float32Mono[j];
                    count++;
                }
                const sample = count ? (sum / count) : float32Mono[Math.min(start, float32Mono.length - 1)];
                const s = Math.max(-1, Math.min(1, sample));
                out[iOut++] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return out;
        }

        function encodeWav16kMono(int16Samples) {
            const numSamples = int16Samples.length;
            const headerSize = 44;
            const dataSize = numSamples * 2;
            const buffer = new ArrayBuffer(headerSize + dataSize);
            const view = new DataView(buffer);
            const writeString = (offset, str) => { for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i)); };
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + dataSize, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true); // PCM chunk size
            view.setUint16(20, 1, true);  // PCM format
            view.setUint16(22, 1, true);  // channels
            view.setUint32(24, 16000, true); // sample rate
            view.setUint32(28, 16000 * 2, true); // byte rate
            view.setUint16(32, 2, true); // block align
            view.setUint16(34, 16, true); // bits per sample
            writeString(36, 'data');
            view.setUint32(40, dataSize, true);
            // PCM data
            let off = 44;
            for (let i = 0; i < numSamples; i++, off += 2) view.setInt16(off, int16Samples[i], true);
            return new Uint8Array(buffer);
        }

        function emitGroqSegmentIfReady(boundaryIndex) {
            const samplesSinceBoundary = boundaryIndex - groqLastBoundary;
            const msSinceBoundary = (samplesSinceBoundary / 16000) * 1000;
            if (!groqHadSpeech || msSinceBoundary < GROQ_MIN_SEGMENT_MS) return;
            const seg = groqSamples16k.slice(groqLastBoundary, boundaryIndex);
            const wavBytes = encodeWav16kMono(Int16Array.from(seg));
            console.log('[Segmenter] Emit segment', { samples: seg.length, ms: Math.round(msSinceBoundary), bytes: wavBytes.length });
            window.electronAPI.saveAudioSegment(wavBytes);
            groqLastBoundary = boundaryIndex;
            groqHadSpeech = false;
            groqInSilenceMs = 0;
            // Drop older samples to keep memory bounded
            if (groqLastBoundary > 0) {
                groqSamples16k = groqSamples16k.slice(groqLastBoundary);
                groqLastBoundary = 0;
            }
        }

        let beepSound;
        let clackSound;

        async function loadAudio() {
          try {
            // Try base64 first for packaged reliability
            const beepBase64 = await window.electronAPI.getAssetBase64('assets/audio/beep.mp3');
            if (beepBase64) {
              beepSound = new Audio(`data:audio/mpeg;base64,${beepBase64}`);
            } else {
              const beepUrl = await window.electronAPI.getAssetFileUrl('assets/audio/beep.mp3');
              console.warn('Beep base64 missing, using file URL', beepUrl);
              beepSound = new Audio(beepUrl);
            }

            const clackBase64 = await window.electronAPI.getAssetBase64('assets/audio/clack.mp3');
            if (clackBase64) {
              clackSound = new Audio(`data:audio/mpeg;base64,${clackBase64}`);
            } else {
              const clackUrl = await window.electronAPI.getAssetFileUrl('assets/audio/clack.mp3');
              console.warn('Clack base64 missing, using file URL', clackUrl);
              clackSound = new Audio(clackUrl);
            }

            if (beepSound) {
              beepSound.addEventListener('error', (e) => console.error('beep load/play error', e));
              try { beepSound.load(); } catch (_) {}
            }
            if (clackSound) {
              clackSound.addEventListener('error', (e) => console.error('clack load/play error', e));
              try { clackSound.load(); } catch (_) {}
            }
          } catch (error) {
            console.error('Error loading audio assets:', error);
            // Final fallback to file URLs
            try {
              const beepUrl = await window.electronAPI.getAssetFileUrl('assets/audio/beep.mp3');
              beepSound = new Audio(beepUrl);
              const clackUrl = await window.electronAPI.getAssetFileUrl('assets/audio/clack.mp3');
              clackSound = new Audio(clackUrl);
            } catch (e) {
              console.error('Unable to load audio cues via file URLs', e);
            }
          }
        }

        closeBtn.addEventListener('click', () => {
          window.electronAPI.closeWindow();
        });

        settingsIcon.addEventListener('click', () => {
          window.electronAPI.openSettingsWindow();
        });

        helpButton.addEventListener('click', () => {
            window.electronAPI.openExternalLink('https://github.com/3choff/dictate');
        });

        window.electronAPI.onToggleMic(() => {
          micButton.click();
        });

        micButton.addEventListener('click', async () => {
          const isRecording = micButton.classList.contains('recording');

          if (isRecording) {
            if (clackSound) clackSound.play().catch((e) => console.error('clack play failed', e));
          } else {
            if (beepSound) beepSound.play().catch((e) => console.error('beep play failed', e));
          }

          micButton.classList.toggle('recording');

          if ((mediaRecorder && mediaRecorder.state === 'recording') || dgActive || groqActive) {
            try { mediaRecorder.stop(); } catch (e) { /* ignore */ }
            if (dgActive && dgSocket) {
              try { dgSocket.send(JSON.stringify({ type: 'CloseStream' })); } catch (_) {}
              try { dgSocket.close(); } catch (_) {}
              dgSocket = null;
              dgActive = false;
            }
            if (groqActive) {
              try {
                const currentIndex = groqSamples16k.length;
                const msSinceBoundary = ((currentIndex - groqLastBoundary) / 16000) * 1000;
                if (groqHadSpeech && msSinceBoundary >= GROQ_MIN_SEGMENT_MS) {
                  emitGroqSegmentIfReady(currentIndex);
                }
              } catch (_) {}
              try { if (groqProcessor) groqProcessor.disconnect(); } catch (_) {}
              try { if (groqSource) groqSource.disconnect(); } catch (_) {}
              try { if (groqAudioCtx) groqAudioCtx.close(); } catch (_) {}
              groqProcessor = null; groqSource = null; groqAudioCtx = null;
              groqActive = false;
              groqSamples16k = []; groqLastBoundary = 0; groqInSilenceMs = 0; groqHadSpeech = false;
            }
          } else {
            try {
              const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
              const settings = await window.electronAPI.getSettings();
              const dgKey = ((settings && (settings.deepgramApiKey || settings.apiKey)) || '').trim();
              const preserveFormatting = settings && settings.preserveFormatting !== false; // default true
              const useDeepgram = settings.apiService === 'deepgram' && dgKey.length > 0;

              audioChunks = [];

              if (useDeepgram) {
                console.log('[Deepgram] Streaming mode selected');
                dgActive = true;
                const pref = (window.Deepgram && Deepgram.pickPreferredMime) ? Deepgram.pickPreferredMime() : { mimeType: undefined, encoding: undefined };
                mediaRecorder = new MediaRecorder(stream, pref.mimeType ? { mimeType: pref.mimeType } : undefined);

                const wsUrl = (window.Deepgram && Deepgram.buildUrl)
                  ? Deepgram.buildUrl({ encoding: pref.encoding, smart_format: preserveFormatting })
                  : 'wss://api.deepgram.com/v1/listen';
                try {
                  dgSocket = (window.Deepgram && Deepgram.createSocket) ? Deepgram.createSocket(dgKey, wsUrl) : new WebSocket(wsUrl, ['token', dgKey]);
                } catch (e) {
                  console.error('Deepgram WS open failed', e);
                  dgActive = false;
                }

                if (dgSocket) {
                  dgSocket.onopen = () => {
                    mediaRecorder.ondataavailable = (event) => {
                      if (event.data && event.data.size > 0 && dgSocket && dgSocket.readyState === WebSocket.OPEN) {
                        dgSocket.send(event.data);
                      }
                    };
                    try { mediaRecorder.start(250); } catch (e) { mediaRecorder.start(); }
                  };
                  dgSocket.onmessage = (event) => {
                    try {
                      const msg = JSON.parse(event.data);
                      if (msg.type === 'Results' && msg.channel && msg.channel.alternatives && msg.channel.alternatives[0]) {
                        const alt = msg.channel.alternatives[0];
                        if (alt.transcript && (msg.is_final || msg.speech_final)) {
                          const transcript = alt.transcript.trim();
                          const finalTranscript = transcript + ' ';
                          window.electronAPI.insertText(finalTranscript);
                        }
                      }
                    } catch (e) { /* ignore */ }
                  };
                  dgSocket.onerror = (e) => console.error('Deepgram WS error', e);
                  dgSocket.onclose = () => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                      try { mediaRecorder.stop(); } catch (_) {}
                    }
                    dgActive = false;
                    dgSocket = null;
                  };
                } else {
                  mediaRecorder = new MediaRecorder(stream);
                  mediaRecorder.ondataavailable = (event) => { audioChunks.push(event.data); };
                  mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const audioBuffer = await audioBlob.arrayBuffer();
                    const audioData = new Uint8Array(audioBuffer);
                    window.electronAPI.saveAudio(audioData);
                  };
                  mediaRecorder.start();
                }
              } else {
                console.log('[Segmenter] Silence chunker mode selected');
                groqActive = true;
                groqAudioCtx = new (window.AudioContext || window.webkitAudioContext)();
                try { await groqAudioCtx.resume(); } catch (_) {}
                groqSource = groqAudioCtx.createMediaStreamSource(stream);
                const bufferSize = 4096; // ~85ms at 48k
                groqProcessor = groqAudioCtx.createScriptProcessor(bufferSize, 1, 1);
                let lastDebugLogTs = 0;
                groqProcessor.onaudioprocess = (ev) => {
                  const inBuf = ev.inputBuffer;
                  const mono = mixToMonoFloat32(inBuf);
                  let sumSq = 0;
                  for (let i = 0; i < mono.length; i++) { const s = mono[i]; sumSq += s * s; }
                  const rms = Math.sqrt(sumSq / Math.max(1, mono.length));
                  const db = dbfsFromRms(rms);
                  const frameMs = (mono.length / inBuf.sampleRate) * 1000;
                  if (db < GROQ_SILENCE_DB) {
                    groqInSilenceMs += frameMs;
                  } else {
                    groqInSilenceMs = 0;
                    groqHadSpeech = true;
                  }
                  const now = performance.now();
                  if (now - lastDebugLogTs > 1000) {
                    console.debug('[Segmenter] dB:', Math.round(db), 'silenceMs:', Math.round(groqInSilenceMs), 'hadSpeech:', groqHadSpeech);
                    lastDebugLogTs = now;
                  }
                  const int16 = downsampleTo16kInt16(mono, inBuf.sampleRate);
                  for (let i = 0; i < int16.length; i++) groqSamples16k.push(int16[i]);
                  const currentIndex = groqSamples16k.length;
                  const currentMsSinceBoundary = ((currentIndex - groqLastBoundary) / 16000) * 1000;
                  if (groqInSilenceMs >= GROQ_SILENCE_MS && groqHadSpeech) {
                    emitGroqSegmentIfReady(currentIndex);
                  } else if (groqHadSpeech && currentMsSinceBoundary >= GROQ_MAX_SEGMENT_MS) {
                    emitGroqSegmentIfReady(currentIndex);
                  }
                };
                // Important: connect nodes so onaudioprocess fires
                try { groqSource.connect(groqProcessor); } catch (_) {}
                try { groqProcessor.connect(groqAudioCtx.destination); } catch (_) {}
              }
            } catch (err) {
              console.error('Error accessing microphone:', err);
              micButton.classList.remove('recording');
            }
          }
        });

        loadAudio();
      });
    </script>
</body>
</html>
